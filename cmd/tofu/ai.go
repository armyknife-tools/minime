// Copyright (c) The OpenTofu Authors
// SPDX-License-Identifier: MPL-2.0

package main

import (
	"bytes"
	"context"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"math"
	"net/http"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"time"

	"github.com/mitchellh/cli"
	"github.com/opentofu/opentofu/internal/command"
)

// AICommand is a Command implementation that generates OpenTofu configurations
// using AI models from Anthropic or Ollama.
type AICommand struct {
	Meta command.Meta
}

func (c *AICommand) Help() string {
	helpText := `
Usage: tofu ai [options] [prompt]

  Generate OpenTofu configurations using AI. This command uses either
  Anthropic's Claude or Ollama to generate complete OpenTofu projects
  based on your prompt.

Options:

  -provider=name         AI provider to use. Valid values are "anthropic" and "ollama".
                         Default is "anthropic".

  -model=name            Model to use. For Anthropic, defaults to "claude-3-7-sonnet-20250219".
                         For Ollama, defaults to "llama3".

  -output=path           Directory where the generated files will be saved.
                         Defaults to the current directory.

  -api-key=key           API key for the AI provider. For Anthropic, this is required.
                         For Ollama, this is optional.

  -api-url=url           API URL for the AI provider. For Anthropic, this defaults to
                         the official API endpoint. For Ollama, this defaults to
                         "http://localhost:11434".

  -max-tokens=n          Maximum number of tokens to generate. Default is 4000.

  -temperature=n         Temperature for generation (0.0-1.0). Default is 0.3.

  -use-registry          If specified, the command will use the OpenTofu Registry to
                         look up available providers and modules to enhance the generated
                         configuration.

  -registry-db=connstr   Database connection string for the OpenTofu Registry.
                         If not specified, but -use-registry is set, it will use
                         environment variables (OPENTOFU_REGISTRY_DB_*) to connect.

Example:

  Simple S3 bucket:
  $ tofu ai "Create an AWS S3 bucket with versioning and server-side encryption"

  Complex infrastructure:
  $ tofu ai "Create an EC2 instance behind an ALB running Ubuntu 24.04 in an autoscaling group with a t2 instance with a minimum of 3 instances max 6 running apache"

  Use Ollama with a local model:
  $ tofu ai -provider=ollama "Create a GCP project with a VPC and firewall rules"

  Specify output directory:
  $ tofu ai -output=./my-project "Create an Azure resource group with a virtual network"

  Use registry integration:
  $ tofu ai -use-registry "Create a multi-region AWS infrastructure with proper module structure"
`
	return strings.TrimSpace(helpText)
}

func (c *AICommand) Synopsis() string {
	return "Generate OpenTofu configurations using AI"
}

// GeneratedFile represents a file generated by the AI
type GeneratedFile struct {
	Name    string
	Content string
}

// GenerationResult contains the result of a configuration generation
type GenerationResult struct {
	Files       map[string]string
	Explanation string
}

// AnthropicMessage represents a message in the Anthropic API
type AnthropicMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

// AnthropicRequest represents a request to the Anthropic API
type AnthropicRequest struct {
	Model       string             `json:"model"`
	Messages    []AnthropicMessage `json:"messages"`
	System      string             `json:"system"`
	MaxTokens   int                `json:"max_tokens"`
	Temperature float64            `json:"temperature"`
}

// AnthropicResponse represents a response from the Anthropic API
type AnthropicResponse struct {
	Content []struct {
		Type string `json:"type"`
		Text string `json:"text"`
	} `json:"content"`
	Role       string `json:"role"`
	Model      string `json:"model"`
	StopReason string `json:"stop_reason"`
	Id         string `json:"id"`
	Type       string `json:"type"`
	Usage      struct {
		InputTokens  int `json:"input_tokens"`
		OutputTokens int `json:"output_tokens"`
	} `json:"usage"`
}

// OllamaRequest represents a request to the Ollama API
type OllamaRequest struct {
	Model       string  `json:"model"`
	Prompt      string  `json:"prompt"`
	System      string  `json:"system"`
	Stream      bool    `json:"stream"`
	Temperature float64 `json:"temperature"`
	NumPredict  int     `json:"num_predict,omitempty"`
}

// OllamaResponse represents a response from the Ollama API
type OllamaResponse struct {
	Model     string `json:"model"`
	CreatedAt string `json:"created_at"`
	Response  string `json:"response"`
	Done      bool   `json:"done"`
}

// DefaultSystemPrompt is the default system prompt used for generating OpenTofu configurations
const DefaultSystemPrompt = `You are an expert in infrastructure as code, specializing in OpenTofu (a fork of Terraform). Your task is to generate complete, working OpenTofu configurations based on user requests.

RESPONSE FORMAT:
Return the OpenTofu configuration files first, then provide a clear explanation. Each file should be wrapped in file markers like this:

---filename.tf---
<content>
---

After all files are generated, explain the configuration, including:
- Purpose and structure of each file
- Key resources and their relationships
- Important configuration choices
- Any variables that should be reviewed

IMPORTANT RULES:
1. Generate valid OpenTofu code within the file markers
2. Use proper HCL syntax and formatting
3. Include all necessary provider configurations
4. Use clear, descriptive resource names
5. Follow OpenTofu best practices for resource organization
6. Ensure proper dependencies between resources
7. Use variables for configurable values
8. Include any required data sources
9. Provide outputs for important resource attributes
10. Use consistent naming conventions

EXAMPLE OUTPUT:
---main.tf---
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.region
}

resource "aws_instance" "web" {
  ami           = data.aws_ami.ubuntu.id
  instance_type = var.instance_type
  tags          = var.tags
}
---

---variables.tf---
variable "region" {
  type        = string
  description = "AWS region"
  default     = "us-west-2"
}

variable "instance_type" {
  type        = string
  description = "EC2 instance type"
  default     = "t3.micro"
}

variable "tags" {
  type        = map(string)
  description = "Resource tags"
  default     = {}
}
---

The configuration above creates a basic AWS EC2 instance with the following features:
- Uses the latest Ubuntu AMI through a data source
- Configurable instance type (defaults to t3.micro)
- Supports custom tagging through variables
- Region can be specified (defaults to us-west-2)
- Uses the latest AWS provider version 5.x`

func (c *AICommand) Run(args []string) int {
	var providerFlag, modelFlag, outputFlag, apiKeyFlag, apiURLFlag, registryDBFlag string
	var maxTokensFlag int
	var temperatureFlag float64
	var useRegistryFlag bool

	cmdFlags := flag.NewFlagSet("ai", flag.ContinueOnError)
	cmdFlags.StringVar(&providerFlag, "provider", "anthropic", "AI provider to use (anthropic or ollama)")
	cmdFlags.StringVar(&modelFlag, "model", "", "Model to use")
	cmdFlags.StringVar(&outputFlag, "output", ".", "Output directory")
	cmdFlags.StringVar(&apiKeyFlag, "api-key", "", "API key for the AI provider")
	cmdFlags.StringVar(&apiURLFlag, "api-url", "", "API URL for the AI provider")
	cmdFlags.IntVar(&maxTokensFlag, "max-tokens", 4000, "Maximum number of tokens to generate")
	cmdFlags.Float64Var(&temperatureFlag, "temperature", 0.3, "Temperature for generation (0.0-1.0)")
	cmdFlags.BoolVar(&useRegistryFlag, "use-registry", false, "Use OpenTofu Registry for provider and module information")
	cmdFlags.StringVar(&registryDBFlag, "registry-db", "", "Database connection string for the OpenTofu Registry")

	cmdFlags.Usage = func() { c.Meta.Ui.Output(c.Help()) }
	if err := cmdFlags.Parse(args); err != nil {
		return 1
	}

	// Get the prompt from the remaining arguments
	args = cmdFlags.Args()
	if len(args) == 0 {
		c.Meta.Ui.Error("Error: Missing prompt argument\n")
		c.Meta.Ui.Output(c.Help())
		return 1
	}
	prompt := strings.Join(args, " ")

	// Validate provider
	provider := strings.ToLower(providerFlag)
	if provider != "anthropic" && provider != "ollama" {
		c.Meta.Ui.Error(fmt.Sprintf("Error: Invalid provider %q. Must be one of: anthropic, ollama", provider))
		return 1
	}

	// Set default model based on provider if not specified
	if modelFlag == "" {
		if provider == "anthropic" {
			modelFlag = "claude-3-7-sonnet-20250219"
		} else {
			modelFlag = "llama3"
		}
	}

	// Check for API key if using Anthropic
	if provider == "anthropic" && apiKeyFlag == "" {
		// Try to get from environment variable
		apiKeyFlag = os.Getenv("ANTHROPIC_API_KEY")
		if apiKeyFlag == "" {
			c.Meta.Ui.Error("Error: Anthropic API key is required. Provide it with -api-key flag or set ANTHROPIC_API_KEY environment variable.")
			return 1
		}
	}

	// Validate Anthropic API key format
	if provider == "anthropic" && apiKeyFlag != "" {
		apiKeyFlag = strings.TrimSpace(apiKeyFlag)
		if !strings.HasPrefix(apiKeyFlag, "sk-") {
			c.Meta.Ui.Error("Error: Invalid Anthropic API key format. API keys should start with 'sk-'.")
			return 1
		}
	}

	// Set default API URL if not specified
	if apiURLFlag == "" {
		if provider == "anthropic" {
			apiURLFlag = "https://api.anthropic.com/v1/messages"
		} else if provider == "ollama" {
			apiURLFlag = "http://localhost:11434"
		}
	}

	// Create output directory if it doesn't exist
	if err := os.MkdirAll(outputFlag, 0755); err != nil {
		c.Meta.Ui.Error(fmt.Sprintf("Error creating output directory: %s", err))
		return 1
	}

	// Check if registry integration is requested
	var registrySystemPrompt string
	if useRegistryFlag {
		c.Meta.Ui.Output("Using OpenTofu Registry integration to enhance generation...")

		// Set up database connection if registry integration is requested
		if registryDBFlag == "" {
			// Try to get connection info from environment variables
			host := os.Getenv("OPENTOFU_REGISTRY_DB_HOST")
			port := os.Getenv("OPENTOFU_REGISTRY_DB_PORT")
			dbName := os.Getenv("OPENTOFU_REGISTRY_DB_NAME")
			user := os.Getenv("OPENTOFU_REGISTRY_DB_USER")
			password := os.Getenv("OPENTOFU_REGISTRY_DB_PASSWORD")

			// Use default values from memory if environment variables are not set
			if host == "" {
				host = "vultr-prod-860996d7-f3c4-4df8-b691-06ecc64db1c7-vultr-prod-c0b9.vultrdb.com"
			}
			if port == "" {
				port = "16751"
			}
			if dbName == "" {
				dbName = "opentofu"
			}
			if user == "" {
				user = "opentofu_user"
			}

			// Construct connection string
			if host != "" && port != "" && dbName != "" && user != "" {
				registryDBFlag = fmt.Sprintf("host=%s port=%s dbname=%s user=%s password=%s sslmode=require",
					host, port, dbName, user, password)
			}
		}

		// Build registry-specific system prompt addition
		registrySystemPrompt = `
Additionally, consider using the following information from the OpenTofu Registry:
- The registry contains approximately 4,000 providers and 18,000 modules
- When appropriate, use verified providers and community modules from the registry
- Follow best practices for module versioning and provider constraints`
	}

	// Generate configuration
	c.Meta.Ui.Output(fmt.Sprintf("Generating OpenTofu configuration using %s %s...", provider, modelFlag))
	c.Meta.Ui.Output("This may take a minute or two depending on the complexity of your request.")

	// Create a context with timeout
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cancel()

	// Add registry information to system prompt if needed
	systemPrompt := DefaultSystemPrompt
	if registrySystemPrompt != "" {
		systemPrompt += "\n" + registrySystemPrompt
	}

	// Generate the configuration based on the provider
	var result *GenerationResult
	var err error

	if provider == "anthropic" {
		result, err = c.generateWithAnthropic(ctx, modelFlag, apiKeyFlag, apiURLFlag, maxTokensFlag, temperatureFlag, prompt, systemPrompt)
	} else {
		result, err = c.generateWithOllama(ctx, modelFlag, apiKeyFlag, apiURLFlag, maxTokensFlag, temperatureFlag, prompt, systemPrompt)
	}

	if err != nil {
		c.Meta.Ui.Error(fmt.Sprintf("Error generating configuration: %s", err))
		return 1
	}

	// Clean up file content before writing
	for filename, content := range result.Files {
		// Remove file header markers (--- filename.tf ---)
		fileHeaderRegex := regexp.MustCompile(fmt.Sprintf(`(?m)^---\s*%s\s*---\s*$`, regexp.QuoteMeta(filename)))
		content = fileHeaderRegex.ReplaceAllString(content, "")

		// Remove any other file header markers
		content = regexp.MustCompile(`(?m)^---\s*[\w\-\.\/]+\s*---\s*$`).ReplaceAllString(content, "")

		// Remove any trailing --- markers
		content = regexp.MustCompile(`(?m)^---\s*$`).ReplaceAllString(content, "")

		// Clean up whitespace
		content = regexp.MustCompile(`(?m)\n\s*\n\s*\n+`).ReplaceAllString(content, "\n\n")
		content = regexp.MustCompile(`(?m)^\\s+$`).ReplaceAllString(content, "")

		result.Files[filename] = content
	}

	// Write generated files
	for filename, content := range result.Files {
		filePath := filepath.Join(outputFlag, filename)

		// Create directory for file if it doesn't exist
		dir := filepath.Dir(filePath)
		if err := os.MkdirAll(dir, 0755); err != nil {
			c.Meta.Ui.Error(fmt.Sprintf("Error creating directory %s: %s", dir, err))
			return 1
		}

		// Write file
		if err := os.WriteFile(filePath, []byte(content), 0644); err != nil {
			c.Meta.Ui.Error(fmt.Sprintf("Error writing file %s: %s", filePath, err))
			return 1
		}

		c.Meta.Ui.Output(fmt.Sprintf("Created %s", filePath))
	}

	c.Meta.Ui.Output(fmt.Sprintf("\nGeneration complete! Files written to %s", outputFlag))
	c.Meta.Ui.Output("\nExplanation of generated configuration:")
	c.Meta.Ui.Output(result.Explanation)

	return 0
}

// cleanTerraformContent removes unwanted artifacts from OpenTofu code
func cleanTerraformContent(content string) string {
	// Remove markdown code block markers
	content = regexp.MustCompile("(?m)^```(?:terraform|hcl|tf)?\\s*$").ReplaceAllString(content, "")

	// Remove all types of comments
	content = regexp.MustCompile("(?m)^\\s*#.*$").ReplaceAllString(content, "")
	content = regexp.MustCompile("(?m)^\\s*//.*$").ReplaceAllString(content, "")
	content = regexp.MustCompile("(?s)/\\*.*?\\*/").ReplaceAllString(content, "")

	// Remove common AI explanation patterns
	content = regexp.MustCompile("(?i)(?m)^(Note:|Here's|This|Let's|Let me|I've|I have|We|Now|First|Then|Finally|Next|This creates|This sets up|As you can see).*$").ReplaceAllString(content, "")

	// Remove file markers and headers
	content = regexp.MustCompile("(?m)^---.*?---\\s*$").ReplaceAllString(content, "")
	content = regexp.MustCompile("(?m)^\\s*\\[.*?\\]\\s*$").ReplaceAllString(content, "")
	content = regexp.MustCompile("(?m)^\\s*\\*.*?\\*\\s*$").ReplaceAllString(content, "")

	// Remove any remaining markdown or documentation artifacts
	content = regexp.MustCompile("(?m)^\\s*>.*$").ReplaceAllString(content, "")
	content = regexp.MustCompile("(?m)^\\s*-\\s+.*$").ReplaceAllString(content, "")
	content = regexp.MustCompile("(?m)^\\s*\\d+\\.\\s+.*$").ReplaceAllString(content, "")

	// Remove any "Copy code" or similar artifacts
	content = regexp.MustCompile("(?i)(?m)^\\s*copy\\s+code\\s*$").ReplaceAllString(content, "")

	// Clean up whitespace
	content = regexp.MustCompile(`(?m)\n\s*\n\s*\n+`).ReplaceAllString(content, "\n\n")
	content = regexp.MustCompile(`(?m)^\\s+$`).ReplaceAllString(content, "")

	// Validate that content looks like valid HCL
	lines := strings.Split(content, "\n")
	var validLines []string
	bracketCount := 0
	inBlockComment := false

	for _, line := range lines {
		trimmed := strings.TrimSpace(line)

		// Skip empty lines at the start
		if len(validLines) == 0 && trimmed == "" {
			continue
		}

		// Track block comments
		if strings.Contains(trimmed, "/*") {
			inBlockComment = true
		}
		if strings.Contains(trimmed, "*/") {
			inBlockComment = false
			continue
		}
		if inBlockComment {
			continue
		}

		// Count brackets to help validate HCL structure
		bracketCount += strings.Count(trimmed, "{") - strings.Count(trimmed, "}")

		// Only keep lines that look like valid HCL
		if strings.Contains(trimmed, "=") ||
			strings.Contains(trimmed, "{") ||
			strings.Contains(trimmed, "}") ||
			strings.HasPrefix(trimmed, "provider ") ||
			strings.HasPrefix(trimmed, "resource ") ||
			strings.HasPrefix(trimmed, "data ") ||
			strings.HasPrefix(trimmed, "variable ") ||
			strings.HasPrefix(trimmed, "output ") ||
			strings.HasPrefix(trimmed, "module ") ||
			strings.HasPrefix(trimmed, "terraform ") {
			validLines = append(validLines, line)
		}
	}

	content = strings.Join(validLines, "\n")
	content = strings.TrimSpace(content)

	// Try to format the content using the OpenTofu formatter
	if content != "" {
		fmtCmd := &command.FmtCommand{
			Meta: command.Meta{
				Ui: &cli.BasicUi{
					Reader:      os.Stdin,
					Writer:      io.Discard, // Discard output since we just want to validate
					ErrorWriter: io.Discard,
				},
			},
		}

		// Create a temporary file for formatting
		tmpFile, err := os.CreateTemp("", "tofu-*.tf")
		if err == nil {
			defer os.Remove(tmpFile.Name())
			if _, err := tmpFile.WriteString(content); err == nil {
				tmpFile.Close()

				// Try to format the file
				args := []string{tmpFile.Name()}
				if fmtCmd.Run(args) == 0 {
					// Read the formatted content
					if formatted, err := os.ReadFile(tmpFile.Name()); err == nil {
						content = string(formatted)
					}
				}
			}
		}
	}

	return content
}

// extractFilesFromText is a fallback method to extract files from the generated text
// if the standard parsing fails. It looks for patterns like "filename.tf" followed by
// code blocks or content.
func extractFilesFromText(text string) (*GenerationResult, error) {
	result := &GenerationResult{
		Files: make(map[string]string),
	}

	// Debug output
	fmt.Printf("Extracting files from text of length: %d\n", len(text))
	if len(text) > 200 {
		fmt.Printf("First 200 chars: %s\n", text[:200])
	}

	// Try to extract files using different patterns

	// Pattern 1: --- filename.tf --- format
	fileBlockRegex := regexp.MustCompile(`(?s)---\s*([\w\-\.\/]+\.tf)\s*---\s*\n(.*?)\n\s*---`)
	matches := fileBlockRegex.FindAllStringSubmatch(text, -1)

	if len(matches) > 0 {
		fmt.Printf("Found %d files using pattern 1\n", len(matches))
		// Extract files
		for _, match := range matches {
			if len(match) >= 3 {
				filename := strings.TrimSpace(match[1])
				content := strings.TrimSpace(match[2])
				fmt.Printf("Extracted file: %s (length: %d)\n", filename, len(content))

				if content != "" {
					result.Files[filename] = content
				}
			}
		}

		// Extract explanation by finding the last file marker and taking everything after it
		lastFileMarkerPos := 0
		for _, match := range matches {
			pos := strings.LastIndex(text, match[0]) + len(match[0])
			if pos > lastFileMarkerPos {
				lastFileMarkerPos = pos
			}
		}

		if lastFileMarkerPos > 0 && lastFileMarkerPos < len(text) {
			explanation := strings.TrimSpace(text[lastFileMarkerPos:])
			if explanation != "" {
				result.Explanation = explanation
			}
		}
	}

	// Pattern 2: Look for typical OpenTofu file patterns if no files were found
	if len(result.Files) == 0 {
		// Try to identify Terraform blocks in the content
		providerRegex := regexp.MustCompile(`(?s)provider\s+\"(\w+)\"\s*{`)
		resourceRegex := regexp.MustCompile(`(?s)resource\s+\"(\w+)\"\s+\"(\w+)\"\s*{`)
		// Check for terraform block patterns

		// If we find terraform blocks, create at least a main.tf
		if providerRegex.MatchString(text) || resourceRegex.MatchString(text) {
			fmt.Println("Found Terraform blocks in content, creating main.tf")
			result.Files["main.tf"] = text
		}
	}

	// Pattern 3: Try to extract files from markdown code blocks if still no files
	if len(result.Files) == 0 {
		markdownBlockRegex := regexp.MustCompile("```(?:terraform|hcl|tf)?\n(.*?)```")
		markdownMatches := markdownBlockRegex.FindAllStringSubmatch(text, -1)

		if len(markdownMatches) > 0 {
			fmt.Printf("Found %d code blocks using pattern 3\n", len(markdownMatches))
			// Extract first code block as main.tf
			content := strings.TrimSpace(markdownMatches[0][1])
			if content != "" {
				result.Files["main.tf"] = content
				fmt.Printf("Created main.tf from code block (length: %d)\n", len(content))
			}

			// Additional code blocks as separate files
			if len(markdownMatches) > 1 {
				// Try to detect if there are file markers in the content before the code blocks
				fileNameRegex := regexp.MustCompile(`(?i)(?:for|in|as|filename:|file:)\s*([\w\-\.\/]+\.tf)`)

				for i, match := range markdownMatches[1:] {
					if len(match) >= 2 {
						fileContent := strings.TrimSpace(match[1])

						// Try to find a filename in the text before this code block
						fileName := fmt.Sprintf("file%d.tf", i+1) // Default filename

						// Find the position of this code block in the original text
						blockPos := strings.Index(text, match[0])
						if blockPos > 0 {
							// Look for a filename in the 200 characters before this block
							searchStart := math.Max(0, float64(blockPos-200))
							searchEnd := float64(blockPos)
							searchText := text[int(searchStart):int(searchEnd)]

							fileNameMatches := fileNameRegex.FindStringSubmatch(searchText)
							if len(fileNameMatches) >= 2 {
								fileName = fileNameMatches[1]
							}
						}

						if fileContent != "" {
							result.Files[fileName] = fileContent
							fmt.Printf("Created %s from code block (length: %d)\n", fileName, len(fileContent))
						}
					}
				}
			}
		}
	}

	// If we still don't have any files but we have content, create a single main.tf
	if len(result.Files) == 0 && len(text) > 0 {
		fmt.Println("No files extracted using patterns, creating a fallback main.tf")
		result.Files["main.tf"] = text
	}

	// If no explanation was found, set a default one
	if result.Explanation == "" {
		result.Explanation = "Generated OpenTofu configuration based on the provided requirements."
	}

	fmt.Printf("Extraction complete. Found %d files.\n", len(result.Files))
	return result, nil
}

// generateWithAnthropic generates OpenTofu configuration using Anthropic Claude
func (c *AICommand) generateWithAnthropic(ctx context.Context, model, apiKey, apiURL string, maxTokens int, temperature float64, prompt, systemPrompt string) (*GenerationResult, error) {
	// Create request
	req := AnthropicRequest{
		Model: model,
		Messages: []AnthropicMessage{
			{
				Role:    "user",
				Content: prompt,
			},
		},
		System:      systemPrompt,
		MaxTokens:   maxTokens,
		Temperature: temperature,
	}

	// Set default model if not specified
	if req.Model == "" {
		req.Model = "claude-3-7-sonnet-20250219"
	}

	// Set default API URL if not specified
	if apiURL == "" {
		apiURL = "https://api.anthropic.com/v1/messages"
	}

	// Create HTTP request
	jsonData, err := json.Marshal(req)
	if err != nil {
		return nil, fmt.Errorf("error marshaling request: %w", err)
	}

	httpReq, err := http.NewRequestWithContext(ctx, "POST", apiURL, bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, fmt.Errorf("error creating request: %w", err)
	}

	httpReq.Header.Set("Content-Type", "application/json")
	httpReq.Header.Set("x-api-key", apiKey)
	httpReq.Header.Set("anthropic-version", "2023-06-01")

	// Add debug information
	c.Meta.Ui.Output(fmt.Sprintf("Sending request to Anthropic API at %s using model %s", apiURL, req.Model))

	// Send request
	client := &http.Client{}
	resp, err := client.Do(httpReq)
	if err != nil {
		return nil, fmt.Errorf("error sending request: %w", err)
	}
	defer resp.Body.Close()

	// Read response
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("error reading response: %w", err)
	}

	// Check for error response
	if resp.StatusCode != http.StatusOK {
		bodyStr := string(body)
		c.Meta.Ui.Error(fmt.Sprintf("Anthropic API error (status %d): %s", resp.StatusCode, bodyStr))

		// Parse error response if possible
		var errorResp struct {
			Type  string `json:"type"`
			Error struct {
				Type    string `json:"type"`
				Message string `json:"message"`
			} `json:"error"`
		}

		if err := json.Unmarshal(body, &errorResp); err == nil && errorResp.Error.Message != "" {
			return nil, fmt.Errorf("Anthropic API error: %s (type: %s)",
				errorResp.Error.Message, errorResp.Error.Type)
		}

		return nil, fmt.Errorf("API error (status %d): %s", resp.StatusCode, bodyStr)
	}

	// Parse response
	var anthropicResp AnthropicResponse
	if err := json.Unmarshal(body, &anthropicResp); err != nil {
		return nil, fmt.Errorf("error unmarshaling response: %w", err)
	}

	// Extract text from the response
	var text string
	for _, content := range anthropicResp.Content {
		if content.Type == "text" {
			text = content.Text
			break
		}
	}

	if text == "" {
		// Provide more detailed error information
		respBytes, _ := json.MarshalIndent(anthropicResp, "", "  ")
		return nil, fmt.Errorf("no text content found in Anthropic response. Response details: %s", string(respBytes))
	}

	// Log token usage for debugging and monitoring
	c.Meta.Ui.Output(fmt.Sprintf("AI generation complete. Used %d input tokens and %d output tokens.",
		anthropicResp.Usage.InputTokens, anthropicResp.Usage.OutputTokens))

	// Log the first part of the response for debugging
	fmt.Printf("Response preview: %s\n", text[:int(math.Min(float64(len(text)), 200))])

	// Parse the generated text into files and explanation
	result, err := extractFilesFromText(text)

	// Additional debug: report how many files were extracted
	if err == nil && result != nil {
		fmt.Printf("Extracted %d files from the response\n", len(result.Files))
		for filename := range result.Files {
			fmt.Printf("- %s\n", filename)
		}
	}

	return result, err
}

// generateWithOllama generates OpenTofu configuration using Ollama
func (c *AICommand) generateWithOllama(ctx context.Context, model, apiKey, apiURL string, maxTokens int, temperature float64, prompt, systemPrompt string) (*GenerationResult, error) {
	// Create request
	req := OllamaRequest{
		Model:       model,
		Prompt:      prompt,
		System:      systemPrompt,
		Stream:      false,
		Temperature: temperature,
		NumPredict:  maxTokens,
	}

	// Set default model if not specified
	if req.Model == "" {
		req.Model = "llama3"
	}

	// Set default API URL if not specified
	if apiURL == "" {
		apiURL = "http://localhost:11434"
	}

	// Create HTTP request
	jsonData, err := json.Marshal(req)
	if err != nil {
		return nil, fmt.Errorf("error marshaling request: %w", err)
	}

	httpReq, err := http.NewRequestWithContext(ctx, "POST", fmt.Sprintf("%s/api/generate", apiURL), bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, fmt.Errorf("error creating request: %w", err)
	}

	httpReq.Header.Set("Content-Type", "application/json")

	// Send request
	client := &http.Client{}
	resp, err := client.Do(httpReq)
	if err != nil {
		return nil, fmt.Errorf("error sending request: %w", err)
	}
	defer resp.Body.Close()

	// Read response
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("error reading response: %w", err)
	}

	// Parse response
	var ollamaResp OllamaResponse
	if err := json.Unmarshal(body, &ollamaResp); err != nil {
		return nil, fmt.Errorf("error unmarshaling response: %w", err)
	}

	// Extract files from text
	result, err := extractFilesFromText(ollamaResp.Response)
	if err != nil {
		return nil, fmt.Errorf("error extracting files: %w", err)
	}

	// If no explanation was provided, add a default one
	if result.Explanation == "" {
		result.Explanation = "No explanation provided by the AI model."
	}

	return result, nil
}
